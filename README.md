# Emergency Dispatch Simulation

This project is a discrete-event simulation that compares two dispatch policies for fire emergencies using **empirical (data-driven)** timing distributions derived from **real Toronto incidents**:

- **Empirical Dispatch** — picks a vehicle based on historical choice probabilities observed in the data, conditioned on which vehicles are available.
- **LBR** — a model-based policy that scores each (area, vehicle) pair using the original prioritization formula, with a **per-area arrival rate** estimated from empirical inter-arrival samples.

The simulator draws **inter-arrival**, **service**, and **response** times from empirical PMFs built from the Toronto dataset.

---

## How it works

1. **Precompute random samples** (`analysis.py` / `empirical_times.py`)
   - **Inter-arrivals**: one stream per **run area (FD_call)** from `empirical_pmf_by_fd_call.csv`.
   - **Service** & **Response**: per **(FD_call, FD_response/vehicle)** from `empirical_pmf.csv`.
   - Samples are packaged into a `PrecomputedTimes` object.

2. **Policies** (`policies.py`)
   - **EmpiricalDispatch**: uses `empirical_dispatch_distribution.csv` to sample the dispatched vehicle given the area and the current **available set**.
   - **LBR**: for each (area, vehicle) pair, the policy computes a **score** that combines two factors:  
     1. The expected chance of a quick arrival, based on the area’s historical arrival rate and the vehicle’s service/response distribution.  
     2. A penalty for longer response times, giving preference to vehicles with shorter 95th-percentile response times.  
     
     In practice, vehicles with higher likelihood of fast arrival and lower response variability are ranked higher, and the best-scoring vehicle is dispatched.

3. **Simulation engine** (`simulation.py`)
   - Event-driven (heap/priority queue).
   - Schedules **one arrival stream per area**; at each arrival, the active policy selects an available vehicle.
   - Draws service/response times from the precomputed pools.
   - Tracks response times, queue length (including **time-weighted average queue**), completions, and simple system utilization.

4. **Experiment driver** (`project.py` / `main.py`)
   - Runs `NUM_REPLICATIONS` per parameter set with **common random numbers** (same precomputed samples fed to all policies in a replication).
   - After each replication, appends **one row** to a single Excel file: `replication_results.xlsx` (**overwritten at the start** of each run).
   - Optionally generates **comparison plots** (`plots.py`) with a bar per policy and **95% CI error bars** for:
     - Average Mean RT
     - Average 90th Percentile RT
     - Average Queue Size (time-weighted)
     - Average Max Queue Size

---

## Inputs (you provide)

Place these files next to the code (or adjust paths in `analysis.py` / `policies.py`):

1) **`empirical_pmf.csv`** — per (area, vehicle) PMFs for service & response.  
   **Columns:** `FD_call, FD_response, Parameter, Value, Probability`  
   **Parameter:** one of `{ SERVICE_MIN, RESPONSE_TIME_MIN }`

2) **`empirical_pmf_by_fd_call.csv`** — per-area PMFs for inter-arrivals.  
   **Columns:** `FD_call, Parameter, Value, Probability`  
   **Parameter:** `INTER_ARRIVAL_MIN`

3) **`empirical_dispatch_distribution.csv`** — empirical dispatch choices.  
   **Columns:** `FD_call, available_set, FD_response, probability`  
   **Note:** `available_set` is a comma-separated list of vehicle labels (e.g., `1,3,7`)

**Notes**
- All IDs are remapped internally to **0-based indices** for speed and consistency.
- Make sure probabilities **sum to 1** within each `(FD_call, …, Parameter)` block.
- Keep time units consistent (the code expects **minutes**).

---

## Outputs

### `replication_results.xlsx` (sheet: `results`)
One **row per replication** per policy comparison, including:

- **Context:** `comparison` (e.g., `EmpiricalDispatch vs LBR`), `param_set`, `replication`
- **Response times:** `p1_percentile_90`, `p2_percentile_90`, `diff_percentile_90`; `p1_mean_RT`, `p2_mean_RT`, `diff_mean_RT`
- **Queues:** `p1_max_queue`, `p2_max_queue`, `diff_max_queue`; `p1_avg_queue`, `p2_avg_queue`, `diff_avg_queue`
- **System:** `p1_system_load`, `p2_system_load`, `diff_system_load`; `p1_total_services`, `p2_total_services`, `diff_total_services`
- **Winners:** `win_p90`, `win_mean`

> The file is **deleted and recreated** at the start of each run to avoid accidental appends across runs.

### Plots (optional)
`plots/` contains 4 PNGs per comparison (bar charts with **95% CI** per bar). Generated by calling `generate_policy_comparison_plots(...)` at the end of `runProject()`.

---

## Project structure

- `main.py` — entry point (calls `runProject()`).
- `project.py` — orchestrates replications, writes the per-rep Excel, and triggers plots.
- `analysis.py` — builds precomputed samples and runs each policy on the same random inputs.
- `simulation.py` — event-driven engine (arrivals, dispatch, queue, completions, metrics).
- `policies.py` — implementations of **EmpiricalDispatch** and **LBR** (plus scaffolding for others).
- `empirical_times.py` — loaders/samplers for inter-arrival & service/response PMFs.
- `empirical_dispatch.py` — loader for the empirical dispatch choice conditioned on availability.
- `plots.py` — comparison bar charts with 95% CI error bars.
- `models.py` — dataclasses & enums for events, vehicles, and precomputed pools.
- `config.py` — simulation knobs (areas, replications, samples, horizon).
- `globals.py` — shared run indices (set/replication) for logging/naming.

---

## Configuration

Edit `config.py` to set:
- `NUM_PARAMETER_SETS`, `NUM_REPLICATIONS`, `NUM_AREA`, `SIMULATION_TIME`, `NUM_SAMPLES`
- any CV / utilization thresholds you use elsewhere.

**Guidance on replications:** start with **30–50**; for tighter P90 precision, increase to **80–150**. You can size `NUM_REPLICATIONS` from a pilot using CI half-width targets.

---
# Empirical Data Generation Scripts

In addition to the main simulation engine, this project includes **two preprocessing scripts** that generate the empirical distributions used by the simulator.

---

## 1. `empirical_distribution.py`

This script prepares **empirical timing distributions** from the Toronto fire dataset:

- **Cleans raw data** (`Pumpers_C31_For_Analysis.xlsx`) by removing negative times and saving `cleaned_Pumpers_C31_For_Analysis.xlsx`.
- **Exports CSVs** used in the simulation:
  - `empirical_pmf.csv` — per `(FD_call, FD_response)` PMFs for service and response times.
  - `empirical_pmf_by_fd_call.csv` — per-station PMFs for inter-arrival times.
  - `empirical_parameters_wide.csv` — wide format for debugging/inspection.

**Functions included:**
- `save_empirical_pmf(...)` and `save_empirical_pmf_by_fd_call(...)` — build PMFs (rounded to 2 decimals).
- `get_empirical_sampler(...)` — builds samplers from empirical ECDFs.
- `generate_interarrival_by_fdcall(...)` / `generate_interarrival_by_fdresponse(...)` — create per-station inter-arrival PMFs and plots.
- `plot_empirical_distributions(...)` — produces ECDF + histogram plots for response, service, and inter-arrival times.

**Outputs:**
- Produces plots and CSVs in designated folders (e.g., `ecdf_hist/`, `interarrival_by_fdcall/`).

These outputs feed directly into the simulation (`empirical_times.py`).

---

## 2. `empirical_policy.py`

This script reconstructs the **empirical dispatch distribution** from historical logs:

- **Adds availability**: computes which vehicles were available at each call using `ALARM_fixed_character` and `CLEAR_TIME_fixed_character`.
- **Builds dispatch PMFs**: for each `(FD_call, available_set)` combination, calculates empirical probabilities of dispatching each vehicle.

**Exports:**
- `empirical_dispatch_distribution.csv` — used by the simulator’s `EmpiricalDispatch` policy.
- Histograms in `dispatch_histograms/` visualizing per-station dispatch probabilities.

**Functions included:**
- `add_available_vehicles_column(...)` — reconstructs per-call available sets.
- `build_empirical_dispatch_distribution(...)` — computes empirical counts/probabilities.
- `plot_dispatch_histograms(...)` — bar charts of dispatch probability per available set.
- `select_vehicle_by_empirical_distribution(...)` — samples a vehicle at runtime given a call and availability.

These outputs feed directly into the simulation (`empirical_dispatch.py`).
